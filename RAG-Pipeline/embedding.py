from tqdm import tqdm
from sentence_transformers import SentenceTransformer

model = SentenceTransformer(model_id)
EMBED_DIM = len(model.encode("Hello World"))

# ğŸ” Define embedding function (batch version)
def embedding(chunks):
    print("ğŸ” Starting embedding process...")

    # Initialize storage lists for batch insert
    ids = []
    texts = []
    filenames = []
    page_numbers = []
    titles = []
    embeddings = []

    # ğŸ” Process chunks with progress bar
    for i, chunk in tqdm(enumerate(chunks), total=len(chunks), desc="Processing chunks"):
        text = chunk.text  # or chunk.page_content if using LangChain

        # ğŸ“ Extract metadata
        raw_metadata = {
            "filename": chunk.meta.origin.filename,
            "page_numbers": str(sorted({
                prov.page_no for item in chunk.meta.doc_items for prov in item.prov
            })),
            "title": chunk.meta.headings[0] if chunk.meta.headings else None,
        }

        # ğŸ§¹ Normalize None values to empty strings
        metadata = {k: (v if v is not None else "") for k, v in raw_metadata.items()}

        # ğŸ§¬ Generate embedding vector
        vector = model.encode(text)  # Replace `model` with your embedding model

        # ğŸ“Œ Append fields
        ids.append(f"chunk-{i}")
        texts.append(text)
        filenames.append(metadata["filename"])
        page_numbers.append(metadata["page_numbers"])
        titles.append(metadata["title"])
        embeddings.append(vector)

    # ğŸ“¥ Batch insert to Chroma
    collection.add(
        ids=ids,
        embeddings=embeddings,
        documents=texts,
        metadatas=[
            {"filename": f, "page_numbers": p, "title": t}
            for f, p, t in zip(filenames, page_numbers, titles)
        ]
    )

    print(f"âœ… {len(ids)} Chunks embedded and stored!")
    print("ğŸ Embedding complete!")
